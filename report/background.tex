\section{Background}

This section describes the main background theory of the Kleenex language and
its application to approximate string matching.

\subsection{Transducers}

Kleenex is a domain-specific language for expressing transducers. The concept
of a transducer extends that of a finite automaton to also include output, that
is, a finite automaton either accepts or rejects a string, whereas a transducer
produces an output string in a language over a given output alphabet.

First we define the notion of a finite state transducer, which is essentially
just a nondeterministic finite automaton (NFA) which can also output a symbol
on each transition.

\begin{definition}[FST]
  A \emph{finite state transducer} $\mathcal{T}$ over an input alphabet
  $\Sigma$ and an output alphabet $\Gamma$ is a structure
  $(\Sigma, \Gamma, Q, q^s, q^f, \Delta)$, where
  \begin{itemize}
      \item $Q$ is a finite set of states,
      \item $q^s, q^f \in Q$ are the initial and final states,
        respectively, and
      \item $\Delta \subseteq Q \times \Sigma[\epsilon] \times
        \Gamma[\epsilon] \times Q$ is the transition relation.
  \end{itemize}
\end{definition}

Here, $\Sigma[\epsilon]$ denotes the alphabet $\Sigma$ extended with the empty
string $\epsilon$.

Intuitively, there is the following correspondence between the elements of the
transition relation and the transitions in the drawn diagram of the transducer:
\[
  (q, s, t, q') \in \Delta \quad \Leftrightarrow \quad q \xrightarrow{s/t} q'
\]

In an NFA, multiple paths may lead to an accepting state for a given input
string, but regardless of which accepting path is chosen, the ouput is the
same. In an FST, on the other hand, the path determines the transduced output,
thus the same input string may produce entirely different outputs depending on
the path chosen.

In order to disambiguate between different transductions of the same input
string, we introduce the notion of a normalized FST. To facilitate this, we
also introduce two new symbols $\epsilon_0$ and $\epsilon_1$. Both denote the
empty string, but they serve to distinguish between nondeterministic
$\epsilon$-transitions.

\begin{definition}[NFST]
  A \emph{normalized finite state transducer} is a deterministic FST,
  $T = (\Sigma[\epsilon_0,\epsilon_1], \Gamma, q^s, q^f, \Delta)$, with the
  constraint that $\forall q \in Q$, $q$ is either a choice state, a skip
  state, a symbol state, or the final state.
\end{definition}

The notions of choice, skip, or symbol states are perhaps best conveyed by
illustration, as shown in Figure~\ref{fig:nfst-states}.

\begin{figure}[!ht]
  \centering
  \begin{subfigure}[b]{0.3\textwidth}
    \centering
    \begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=1.0cm,
      semithick, main/.style={circle,draw,minimum width=10pt}]
        \node[main] (q0) {$ $};
        \node       (q1) [right = of q0] {};
        \node       (q2) [below right = of q0] {};
        \path (q0) edge node {$\epsilon_0/\cdot$} (q1)
              (q0) edge node [below left = -2mm, swap]
                   {$\epsilon_1/\cdot$} (q2);
    \end{tikzpicture}
    \caption{A choice state.}
  \end{subfigure}
  ~
  \begin{subfigure}[b]{0.3\textwidth}
    \centering
    \begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=1.0cm,
        semithick, main/.style={circle,draw,minimum width=10pt}]
        \node[main] (q0) {$ $};
        \node       (q1) [right = of q0] {};
        \path (q0) edge node        {$\epsilon/\cdot$} (q1);
    \end{tikzpicture}
    \caption{A skip state.}
  \end{subfigure}
  ~
  \begin{subfigure}[b]{0.3\textwidth}
    \centering
    \begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=1.0cm,
      semithick, main/.style={circle,draw,minimum width=10pt}]
        \node[main] (q0) {$ $};
        \node       (q1) [right = of q0] {};
        \path (q0) edge node {$a/\cdot$} (q1);
    \end{tikzpicture}
    \caption{A symbol state.}
  \end{subfigure}
  \caption{Illustration of choice states, skip states, and symbol states.}
  \label{fig:nfst-states}
\end{figure}

Thus, the set of symbols that any state has transitions on, i.e. the support of
the state, is either just $\epsilon$, exactly $\{\epsilon_0, \epsilon_1\}$,
exactly one $a \in \Sigma$, or $\emptyset$ in the case of the final state. The
idea is that $\epsilon_0$ and $\epsilon_1$ imposes an ordering on the
nondeterministic transitions of the choice states, with $\epsilon_0$ being
preferred over $\epsilon_1$. In order to define this more precisely, we need a
few definitions.

A \emph{path} in a transducer is a sequence of consecutive
transitions
\[
  p_0 \xrightarrow{a_1/b_1} p_1 \xrightarrow{a_2/b_2} \dots
  \xrightarrow{a_n/b_n} p_n
\]
which can be written more compactly as
\[
  p_0 \xrightarrow{a/b} p_n
\]
where $a = a_1a_2 \dots a_n$ is the input string and $b = b_1b_2 \dots b_n$ is
the output string of the path.

Define a mapping from $\Sigma[\epsilon, \epsilon_0, \epsilon_1]$ to
$\mathbf{2}[\epsilon]$, that is, the binary alphabet with $\epsilon$. This
naturally extends to a mapping from strings in the extended input alphabet to
strings of bits. The \emph{greedy leftmost disambiguation strategy} of the NFST
is the strategy that chooses the path with the lexicographically least input
bit string.

% Thus, if we define a mapping from
% $\Sigma[\epsilon, \epsilon_0, \epsilon_1]$ to the binary alphabet with
% $\epsilon$, $\mathbf{2}[\epsilon]$, i.e. strings of bits, then the \emph{greedy
%   leftmost disambiguation strategy} of the NFST is the strategy that chooses
% the path with the lexicographically least bit string.

% \[
%   |\epsilon_0| = 0, \quad |\epsilon_1| = 1, \quad |a| = \epsilon, \forall a
%   \in \Sigma[\epsilon]
% \]

\subsection{Kleenex}

As mentioned previously, Kleenex is a domain-specific programming language for
specifying finite transducers, and specifically the core language directly
encodes NFSTs.

\subsubsection{Core Kleenex}

\begin{definition}[Core Kleenex]
  A core Kleenex term is  \dots
\end{definition}


\subsection{Approximate matching and transduction in Kleenex}

Peter Troelsen describes, in his master's
thesis~\cite{troelsen2016approximate}, an approach to approximate transduction
using Kleenex, by rewriting of core Kleenex programs. This is done by
expressing approximate matching as exact matching through program
transformation. A core Kleenex term that accepts strings of some language $L$
is transformed to another term which accepts strings from $L$ as well as any
string with a distance of at most $k$ to some string in $L$, given some
distance metric.

Troelsen's approach is purely a transformation of the core language, so the
rest of the compilation process and optimizations of the Kleenex compiler
remains unchanged. This means that the transformed transducer will also be
compiled to a streaming string transducer, thus harnessing the high performance
at runtime, but also sufferring during determinization of the transducer. For
this reason, one can speculate that an implementation which works at a deeper
level of the compilation process may be able to optimize things and reduce the
number of generated states and transitions.

% for instance by counting the errors instead of encoding the number of allowed
% errors directly in the program grammar


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
