\section{Background}

This section describes the main background theory of the Kleenex language and
its application to approximate string matching.

\subsection{Transducers}

Kleenex~\cite{grathwohl2016kleenex,soholm2015ordered} is a domain-specific
language for expressing transducers. The concept of a transducer extends that
of a finite automaton to also include output, that is, a finite automaton
either accepts or rejects a string, whereas a transducer produces an output
string in a language over a given output alphabet.

First we define the notion of a finite state transducer, which is essentially
just a nondeterministic finite automaton (NFA) which can also output a symbol
on each transition.

\begin{definition}[FST]
  A \emph{finite state transducer} $\mathcal{T}$ over an input alphabet
  $\Sigma$ and an output alphabet $\Gamma$ is a structure
  $(\Sigma, \Gamma, Q, q^s, q^f, \Delta)$, where
  \begin{itemize}
      \item $Q$ is a finite set of states,
      \item $q^s, q^f \in Q$ are the initial and final states,
        respectively, and
      \item $\Delta \subseteq Q \times \Sigma[\epsilon] \times
        \Gamma[\epsilon] \times Q$ is the transition relation.
  \end{itemize}
\end{definition}

\noindent
Here, $\Sigma[\epsilon]$ denotes the alphabet $\Sigma$ extended with the empty
string $\epsilon$.

Intuitively, there is the following correspondence between the elements of the
transition relation and the transitions in the drawn diagram of the transducer:
\[
  (q, s, t, q') \in \Delta \quad \Leftrightarrow \quad q \xrightarrow{s/t} q'
\]
That is, if $(q, s, t, q') \in \Delta$ then the transducer may transition from
state $q$ to state $q'$ by consuming a symbol $s \in \Sigma[\epsilon]$ and
outputting a symbol $t \in \Gamma[\epsilon]$.

In an NFA, multiple paths may lead to an accepting state for a given input
string, but regardless of which accepting path is chosen, the ouput is the
same. In an FST, on the other hand, the path determines the transduced output,
thus the same input string may produce entirely different outputs depending on
the path chosen.

In order to disambiguate between different transductions of the same input
string, we introduce the notion of a normalized
FST~\cite{grathwohl2016kleenex}. To facilitate this, we also introduce two new
symbols $\epsilon_0$ and $\epsilon_1$. Both denote the empty string, but they
serve to distinguish between nondeterministic $\epsilon$-transitions.

\begin{definition}[NFST]
  A \emph{normalized finite state transducer} is a deterministic FST,
  $\mathcal{T} = (\Sigma[\epsilon_0,\epsilon_1], \Gamma, q^s, q^f, \Delta)$,
  with the constraint that for any state $q$ in $Q$, $q$ is either a choice
  state, a skip state, a symbol state, or the final state.
\end{definition}

The notions of choice, skip, or symbol states are perhaps best conveyed by
illustration, as shown in Figure~\ref{fig:nfst-states}.

\begin{figure}[!ht]
  \centering
  \begin{subfigure}[b]{0.3\textwidth}
    \centering
    \begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=1.0cm,
      semithick, main/.style={circle,draw,minimum width=10pt}]
        \node[main] (q0) {$ $};
        \node       (q1) [right = of q0] {};
        \node       (q2) [below right = of q0] {};
        \path (q0) edge node {$\epsilon_0/\cdot$} (q1)
              (q0) edge node [below left = -2mm, swap]
                   {$\epsilon_1/\cdot$} (q2);
    \end{tikzpicture}
    \caption{A choice state.}
  \end{subfigure}
  ~
  \begin{subfigure}[b]{0.3\textwidth}
    \centering
    \begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=1.0cm,
        semithick, main/.style={circle,draw,minimum width=10pt}]
        \node[main] (q0) {$ $};
        \node       (q1) [right = of q0] {};
        \path (q0) edge node        {$\epsilon/\cdot$} (q1);
    \end{tikzpicture}
    \caption{A skip state.}
  \end{subfigure}
  ~
  \begin{subfigure}[b]{0.3\textwidth}
    \centering
    \begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=1.0cm,
      semithick, main/.style={circle,draw,minimum width=10pt}]
        \node[main] (q0) {$ $};
        \node       (q1) [right = of q0] {};
        \path (q0) edge node {$a/\cdot$} (q1);
    \end{tikzpicture}
    \caption{A symbol state.}
  \end{subfigure}
  \caption{Illustration of choice states, skip states, and symbol states.}
  \label{fig:nfst-states}
\end{figure}

Thus, the set of symbols that any state has transitions on, i.e. the support of
the state, is either just $\epsilon$ (for skip states), exactly
$\{\epsilon_0, \epsilon_1\}$ (for choice states), exactly one $a \in \Sigma$
(for symbol states), or $\emptyset$ in the case of the final state. The idea is
that $\epsilon_0$ and $\epsilon_1$ imposes an ordering on the nondeterministic
transitions of the choice states, with $\epsilon_0$ being preferred over
$\epsilon_1$. In order to define this more precisely, we need a few more
definitions.

A \emph{path} in a transducer is a sequence of consecutive
transitions
\[
  q_0 \xrightarrow{x_1/y_1} q_1 \xrightarrow{x_2/y_2} \dots
  \xrightarrow{x_n/y_n} q_n
\]
which can be written more compactly as
\[
  q_0 \xrightarrow{x/y} q_n
\]
where $x = x_1x_2 \dots x_n$ is the input string and $y = y_1y_2 \dots y_n$ is
the output string of the path.

Define a mapping from $\Sigma[\epsilon, \epsilon_0, \epsilon_1]$ to
$\mathbf{2}[\epsilon]$, that is, the binary alphabet with $\epsilon$. This
naturally extends to a mapping from strings over the extended input alphabet to
strings of bits. The \emph{greedy disambiguation strategy} of an NFST is the
strategy that chooses the path with the lexicographically least input bit
string.

% Thus, if we define a mapping from
% $\Sigma[\epsilon, \epsilon_0, \epsilon_1]$ to the binary alphabet with
% $\epsilon$, $\mathbf{2}[\epsilon]$, i.e. strings of bits, then the \emph{greedy
%   leftmost disambiguation strategy} of the NFST is the strategy that chooses
% the path with the lexicographically least bit string.

% \[
%   |\epsilon_0| = 0, \quad |\epsilon_1| = 1, \quad |a| = \epsilon, \forall a
%   \in \Sigma[\epsilon]
% \]

% TODO: consider including example

% TODO: consider talking about oracle and action automata


\subsection{Kleenex}

As mentioned previously, Kleenex is a domain-specific programming language for
specifying finite transducers, and specifically the core language directly
encodes NFSTs.

\subsubsection{Core Kleenex}

\begin{definition}[Core Kleenex]
  A core Kleenex program is a list of definitions of the form $N := t$, where
  $t$ is generated by the grammar
  \[
    t ::= \epsilon \;|\; N \ |\ \mathtt{a}\; N' \;|\; \mathtt{"b"} N' \;|\;
    N_0|N_1
  \]
  and $a \in \Sigma, b \in \Gamma$, for some given input alphabet $\Sigma$ and
  output alphabet $\Gamma$.
\end{definition}

A core Kleenex program is transformed to an NFST in a direct and
straightforward way: Each nonterminal $N, N', \dots$ maps to a state in the
transducer, the set of states is extended with a final state, and each core
Kleenex definition maps to one or two transitions in the transducer.

% TODO: maybe show mapping of definition to transitions



\subsection{Approximate matching and transduction in Kleenex}

Peter Troelsen describes, in his master's
thesis~\cite{troelsen2016approximate}, an approach to approximate transduction
using Kleenex, by rewriting of core Kleenex programs. This is done by
expressing approximate matching as exact matching through program
transformation. A core Kleenex term that accepts strings of some language $L$
is transformed to another term which accepts strings from $L$ as well as any
string with a distance of at most $k$ to some string in $L$, given some
distance metric.

Troelsen's approach is purely a transformation of the core language, so the
rest of the compilation process and optimizations of the Kleenex compiler
remains unchanged. This means that the transformed transducer will also be
compiled to a streaming string transducer, thus harnessing the high performance
at runtime, but also sufferring during determinization of the transducer. For
this reason, one can speculate that an implementation which works at a deeper
level of the compilation process may be able to optimize things and reduce the
number of generated states and transitions.

% for instance by counting the errors instead of encoding the number of allowed
% errors directly in the program grammar


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
